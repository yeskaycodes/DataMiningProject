{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ea4a5-7515-40a2-96fa-fffad99e0bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import pairwise\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30413ed7-2b0c-4926-83a4-54637f030c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data analysis\n",
    "\n",
    "df = pd.read_csv('raw_titles.csv')\n",
    "df.size\n",
    "print(df)\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Get general information about the dataset\n",
    "print(df.info())\n",
    "\n",
    "# Summary statistics of numerical columns\n",
    "print(df.describe())\n",
    "# Checking for duplicate records\n",
    "df.duplicated().value_counts()\n",
    "import ast  # Library to convert string to list\n",
    "# Convert string representations to lists\n",
    "df['genres'] = df['genres'].apply(ast.literal_eval)\n",
    "df['production_countries'] = df['production_countries'].apply(ast.literal_eval)\n",
    "\n",
    "# Extract the first value from each list in the 'genres' column\n",
    "df['primary_genre'] = df['genres'].apply(lambda x: x[0] if len(x) > 0 else None)\n",
    "df['primary_country'] = df['production_countries'].apply(lambda x: x[0] if len(x) > 0 else None)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "df[['age_certification','imdb_id','title', 'seasons']] = df[['age_certification','imdb_id','title', 'seasons']].fillna('Unknown')\n",
    "df['imdb_score'] = df['imdb_score'].fillna(df['imdb_score'].mode()[0])\n",
    "df['imdb_votes'] = df['imdb_votes'].fillna(df['imdb_votes'].mode()[0])\n",
    "df.dropna(axis=0, inplace = True)\n",
    "\n",
    "# Number of Movies and TV Shows in the dataset\n",
    "plt.figure(figsize=(7,7))\n",
    "df.type.value_counts().plot(kind='pie',autopct='%1.2f%%')\n",
    "plt.ylabel('')\n",
    "plt.title('Movies and TV Shows in the dataset')\n",
    "\n",
    "# Top 5 countries with the highest number movies / TV shows in the dataset\n",
    "plt.figure(figsize=(10,5))\n",
    "df[~(df['primary_country']=='Unknown')].primary_country.value_counts().nlargest(5).plot(kind='barh')\n",
    "plt.title(' Top 5 countries with the highest number of shows')\n",
    "\n",
    "# Histogram of IMDb scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df['imdb_score'], bins=20, kde=True)\n",
    "plt.xlabel('IMDb Score')\n",
    "plt.title('Distribution of IMDb Scores')\n",
    "plt.show()\n",
    "\n",
    "# Box plot of runtime by type (Movie/TV Show)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='type', y='runtime', data=df)\n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Runtime (minutes)')\n",
    "plt.title('Runtime Distribution by Type')\n",
    "plt.show()\n",
    "\n",
    "# Changing the values in the rating column\n",
    "rating_map = {'TV-MA':'Adults',\n",
    "              'R':'Adults',\n",
    "              'PG-13':'Teens',\n",
    "              'TV-14':'Young Adults',\n",
    "              'TV-PG':'Older Kids',\n",
    "              'NR':'Adults',\n",
    "              'TV-G':'Kids',\n",
    "              'TV-Y':'Kids',\n",
    "              'TV-Y7':'Older Kids',\n",
    "              'PG':'Older Kids',\n",
    "              'G':'Kids',\n",
    "              'NC-17':'Adults',\n",
    "              'TV-Y7-FV':'Older Kids',\n",
    "              'UR':'Adults'}\n",
    "\n",
    "df['age_certification'].replace(rating_map, inplace = True)\n",
    "df['age_certification'].unique()\n",
    "\n",
    "# Age ratings for shows in the dataset\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(x='age_certification',data=df)\n",
    "\n",
    "# Number of shows on Netflix for different age groups\n",
    "plt.figure(figsize=(10,5))\n",
    "df.age_certification.value_counts().plot(kind='barh')\n",
    "plt.title('Number of shows on Netflix for different age groups')\n",
    "# Extracting release decade from 'release_year'\n",
    "df['release_decade'] = (df['release_year'] // 10) * 10\n",
    "\n",
    "# Average IMDb scores per release decade\n",
    "avg_scores_per_decade = df.groupby('release_decade')['imdb_score'].mean()\n",
    "print(avg_scores_per_decade)\n",
    "# Visualizing the year in which the movie / tv show was released\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df['release_decade'])\n",
    "plt.title('distribution by released decade')\n",
    "#Separate the data for movies and TV shows\n",
    "movies = df[df['type'] == 'MOVIE']\n",
    "tv_shows = df[df['type'] == 'SHOW']\n",
    "\n",
    "# Count plot of first genre for movies\n",
    "plt.figure(figsize=(10,5))\n",
    "movies.primary_genre.value_counts().nlargest(5).plot(kind='barh')\n",
    "plt.title('Top 5 movie genres')\n",
    "\n",
    "# Count plot of first genre for tv shows\n",
    "plt.figure(figsize=(10,5))\n",
    "tv_shows.primary_genre.value_counts().nlargest(5).plot(kind='barh')\n",
    "plt.title('Top 5 tv show genres')\n",
    "\n",
    "# Box plot of imbd_score by top 5 TV Show Genres\n",
    "top_5_show_genres = tv_shows['primary_genre'].value_counts().head(5).index\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='primary_genre', y='imdb_score', data=tv_shows, order=top_5_show_genres)\n",
    "plt.xlabel('Show Genre')\n",
    "plt.ylabel('imdb_score')\n",
    "plt.title('IMBD Score Distribution by top 5 TV Show Genres')\n",
    "plt.show()\n",
    "\n",
    "# Box plot of imbd_score by top 5 TV Movie Genres\n",
    "top_5_movie_genres = movies['primary_genre'].value_counts().head(5).index\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='primary_genre', y='imdb_score', data=movies, order=top_5_movie_genres)\n",
    "plt.xlabel('Movie Genre')\n",
    "plt.ylabel('imdb_score')\n",
    "plt.title('IMBD Score Distribution by top 5 Movie Genres')\n",
    "plt.show()\n",
    "# Share of top 5 movies genres\n",
    "movies.primary_genre.value_counts().nlargest(5).sum()/len(movies)*100\n",
    "# Share of top 5 show genres\n",
    "tv_shows.primary_genre.value_counts().nlargest(5).sum()/len(tv_shows)*100\n",
    "# Distribution of IMDb scores for movies\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(movies['imdb_score'], bins=20, kde=True, color='blue', label='Movies')\n",
    "plt.xlabel('IMDb Score')\n",
    "plt.title('Distribution of IMDb Scores for Movies')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of IMDb scores for TV shows\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(tv_shows['imdb_score'], bins=20, kde=True, color='red', label='TV Shows')\n",
    "plt.xlabel('IMDb Score')\n",
    "plt.title('Distribution of IMDb Scores for TV Shows')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#Analyze scatter plots to understand the relationship between IMDb scores \n",
    "#and IMDb votes for both types of media.\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(movies['imdb_score'], bins=20, kde=True, color='blue', label='Movies')\n",
    "sns.histplot(tv_shows['imdb_score'], bins=20, kde=True, color='red', label='TV Shows')\n",
    "plt.xlabel('IMDb Score')\n",
    "plt.title('Distribution of IMDb Scores for Movies and TV Shows')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(movies['imdb_votes'], bins=20, kde=True, color='blue', label='Movies')\n",
    "sns.histplot(tv_shows['imdb_votes'], bins=20, kde=True, color='red', label='TV Shows')\n",
    "plt.xlabel('IMDb Votes')\n",
    "plt.title('Distribution of IMDb Votes for Movies and TV Shows')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot of IMDb scores vs. IMDb votes for movies\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='imdb_score', y='imdb_votes', data=movies)\n",
    "plt.title('IMDb Score vs. IMDb Votes for Movies')\n",
    "plt.xlabel('IMDb Score')\n",
    "plt.ylabel('IMDb Votes')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot of IMDb scores vs. IMDb votes for shows\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='imdb_score', y='imdb_votes', data=tv_shows)\n",
    "plt.title('IMDb Score vs. IMDb Votes for TV Shows')\n",
    "plt.xlabel('IMDb Score')\n",
    "plt.ylabel('IMDb Votes')\n",
    "plt.show()\n",
    "# Selecting relevant features for clustering\n",
    "features = df[['release_year', 'runtime','imdb_score', 'imdb_votes']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552f0014-7201-41da-b46c-e9f999a47889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 1 - Kmeans Clustering\n",
    "\n",
    "#Scale the features to have a similar range using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "#Use techniques Elbow Method or Silhouette Score to determine the optimal number of clusters\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Using the Elbow Method to determine the optimal number of clusters\n",
    "inertia = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(scaled_features)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plotting the Elbow Method\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, 11), inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.show()\n",
    "\n",
    "# Plotting Silhouette score for different number of clusters\n",
    "range_n_clusters = range(2,10)\n",
    "silhouette_avg = []\n",
    "for num_clusters in range_n_clusters:\n",
    "  # initialize kmeans\n",
    "  kmeans = KMeans(n_clusters=num_clusters,init='k-means++',random_state=33)\n",
    "  kmeans.fit(scaled_features)\n",
    "  cluster_labels = kmeans.labels_\n",
    " \n",
    "  # silhouette score\n",
    "  silhouette_avg.append(silhouette_score(scaled_features, cluster_labels))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range_n_clusters,silhouette_avg)\n",
    "plt.xlabel('Values of K') \n",
    "plt.ylabel('Silhouette score')\n",
    "plt.title('Silhouette analysis For Optimal k - KMeans clustering')\n",
    "plt.show()\n",
    "# Choose the optimal K value and perform K-means clustering\n",
    "optimal_k = 4  # Example value based on the analysis\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "clusters = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "# Add cluster labels to the DataFrame\n",
    "df['cluster'] = clusters\n",
    "#Visualize the clusters in a 2D space\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df['imdb_score'], df['imdb_votes'], c=clusters, cmap='viridis', alpha=0.5)\n",
    "plt.xlabel('IMDb Score')\n",
    "plt.ylabel('IMDb Votes')\n",
    "plt.title('Clusters of Movies/TV Shows based on IMDb Scores and Votes')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "# Visualizing the clusters (pairwise scatterplot of features)\n",
    "sns.pairplot(df, hue='cluster', vars=features, palette='viridis')\n",
    "plt.show()\n",
    "# Number of movies and tv shows in each cluster\n",
    "plt.figure(figsize=(10,5))\n",
    "q = sns.countplot(x='cluster',data=df, hue='type')\n",
    "plt.title('Number of movies and TV shows in each cluster - Kmeans Clustering')\n",
    "for i in q.patches:\n",
    "  q.annotate(format(i.get_height(), '.0f'), (i.get_x() + i.get_width() / 2., i.get_height()), \n",
    "             ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n",
    "# Number of movies and tv shows in each cluster\n",
    "plt.figure(figsize=(10,5))\n",
    "q = sns.countplot(x='cluster',data=df, hue='release_decade')\n",
    "plt.title('Release Decade in each cluster - Kmeans Clustering')\n",
    "for i in q.patches:\n",
    "  q.annotate(format(i.get_height(), '.0f'), (i.get_x() + i.get_width() / 2., i.get_height()), \n",
    "             ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n",
    "\n",
    "# Evaluation metrics - distortion, Silhouette score\n",
    "kmeans_distortion = kmeans.inertia_\n",
    "kmeans_silhouette_score = silhouette_score(scaled_features, kmeans.labels_)\n",
    "\n",
    "print((kmeans_distortion,kmeans_silhouette_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79629003-5016-445d-b375-70b6c2733e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 2 - KNN MODEL\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a256c2b7-0670-4115-a4dd-594f8d94e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string representations to lists\n",
    "df['genres'] = df['genres'].apply(ast.literal_eval)\n",
    "df['production_countries'] = df['production_countries'].apply(ast.literal_eval)\n",
    "\n",
    "# Extract the first value from each list in the 'genres' column\n",
    "df['first_genre'] = df['genres'].apply(lambda x: x[0] if len(x) > 0 else None)\n",
    "df['production_countries'] = df['production_countries'].apply(lambda x: x[0] if len(x) > 0 else None)\n",
    "\n",
    "print(df[['title', 'first_genre', 'production_countries']])\n",
    "\n",
    "# handling missing value \n",
    "# imputed missing values in 'imdb_score' using the mean value\n",
    "df[['age_certification','imdb_id','title', 'seasons']] = df[['age_certification','imdb_id','title', 'seasons']].fillna('Unknown')\n",
    "df['imdb_score'] = df['imdb_score'].fillna(df['imdb_score'].mode()[0])\n",
    "df['imdb_votes'] = df['imdb_votes'].fillna(df['imdb_votes'].mode()[0])\n",
    "df.dropna(axis=0, inplace = True)\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['release_year', 'age_certification', 'first_genre', 'production_countries']\n",
    "X = pd.get_dummies(df[features])\n",
    "y = df['imdb_score']\n",
    "\n",
    "trainData, validData = train_test_split(df, test_size=0.4, random_state=2)\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=2)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=2)\n",
    "\n",
    "\n",
    "# Create and fit the KNN model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Generate new data point for prediction\n",
    "new_data = {\n",
    "    'release_year': [1997],\n",
    "    'age_certification': ['PG-13'], \n",
    "    'first_genre': ['action'],\n",
    "    'production_countries': ['US']\n",
    "}\n",
    "new_data_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Ensure that the new data point has the same columns as the training data after one-hot encoding\n",
    "new_data_df = pd.get_dummies(new_data_df)\n",
    "new_data_df = new_data_df.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Predict the IMDB_score for the new data point\n",
    "predicted_score = knn_model.predict(new_data_df)\n",
    "\n",
    "# Print the predicted IMDB_score\n",
    "print(\"Predicted IMDb Score:\", predicted_score[0])\n",
    "\n",
    "# Get the neighbors of the new data point\n",
    "neighbors_indices = knn_model.kneighbors(new_data_df, return_distance=False)[0]\n",
    "\n",
    "\n",
    "# Plot the scatter plot to visualize neighbors\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot existing data points\n",
    "ax.scatter(X['release_year'], X['age_certification_PG-13'], y, c='blue', marker='o', label='Existing Data')\n",
    "\n",
    "# Plot the new data point\n",
    "ax.scatter(new_data_df['release_year'], new_data_df['age_certification_PG-13'], predicted_score, c='red', marker='x', s=100, label='New Data Point')\n",
    "\n",
    "# Plot neighbors\n",
    "ax.scatter(X.iloc[neighbors_indices]['release_year'], X.iloc[neighbors_indices]['age_certification_PG-13'], y.iloc[neighbors_indices],\n",
    "           c='green', marker='^', s=50, label='Neighbors')\n",
    "\n",
    "ax.set_xlabel('Release Year')\n",
    "ax.set_ylabel('Age Certification (PG-13)')\n",
    "ax.set_zlabel('IMDb Score')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Predict IMDb scores for the test set\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Train a classifier for different values of k and compute accuracy on validation data\n",
    "k_values = list(range(1, 101))\n",
    "accuracy_results = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict IMDb scores for the validation set\n",
    "    y_pred_valid = knn_model.predict(X_valid)\n",
    "    \n",
    "    # Evaluate the model on validation data\n",
    "    mse_valid = mean_squared_error(y_valid, y_pred_valid)\n",
    "    \n",
    "    # Compute accuracy (you might want to adjust this based on your problem)\n",
    "    accuracy_valid = knn_model.score(X_valid, y_valid)\n",
    "    \n",
    "    accuracy_results.append({\n",
    "        'k': k,\n",
    "        'mse_valid': mse_valid,\n",
    "        'accuracy_valid': accuracy_valid\n",
    "    })\n",
    "\n",
    "# Plotting accuracy for different k values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([result['k'] for result in accuracy_results], [result['accuracy_valid'] for result in accuracy_results], marker='o')\n",
    "plt.title('Accuracy for Different k Values on Validation Data')\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the best k based on the highest accuracy\n",
    "best_k_result = max(accuracy_results, key=lambda x: x['accuracy_valid'])\n",
    "best_k = best_k_result['k']\n",
    "best_accuracy = best_k_result['accuracy_valid']\n",
    "print(f\"Best k: {best_k}, Best Accuracy: {best_accuracy}\")\n",
    "\n",
    "# Create and fit the KNN model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=best_k)  # Using the previously found best k value\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbf3e07-35b7-4d8c-99d6-a13e2cbd8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 3 - REGRESSION TREES\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "! pip install dmba\n",
    "from dmba import classificationSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14384fda-6465-492d-a051-5ca4c80c9e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "def drop_columns(csv_file, columns_to_drop):\n",
    "    # Read CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    df_dropped = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "    return df_dropped\n",
    "\n",
    "csv_file_path = 'raw_titles.csv'\n",
    "columns_to_drop = ['index', 'id', 'title', 'age_certification', 'genres', 'production_countries', 'seasons', 'imdb_id', 'imdb_score', 'imdb_votes']\n",
    "\n",
    "modified_netflix_df = drop_columns(csv_file_path, columns_to_drop)\n",
    "\n",
    "shows_df = modified_netflix_df[modified_netflix_df['type'].str.strip() == 'SHOW'].copy()\n",
    "movies_df = modified_netflix_df[modified_netflix_df['type'].str.strip() == 'MOVIE'].copy()\n",
    "\n",
    "print(\"Modified DataFrame:\")\n",
    "print(modified_netflix_df)\n",
    "\n",
    "print(\"\\nSHOWS DataFrame:\")\n",
    "print(shows_df)\n",
    "\n",
    "print(\"\\nMOVIES DataFrame:\")\n",
    "print(movies_df)\n",
    "\n",
    "# Modified DataFrame by dropping specific columns\n",
    "modified_netflix_df = drop_columns(csv_file_path, columns_to_drop)\n",
    "\n",
    "# Separate DataFrame for shows\n",
    "shows_df = modified_netflix_df[modified_netflix_df['type'].str.strip() == 'SHOW'].copy()\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = shows_df[['release_year']]\n",
    "y = shows_df['runtime']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a regression tree\n",
    "reg_tree = DecisionTreeRegressor(max_depth=2)\n",
    "reg_tree.fit(X_train, y_train)\n",
    "\n",
    "# Visualize the regression tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(reg_tree, feature_names=['Shows Release Year'], filled=True, rounded=True, impurity=False, fontsize=8, precision=0, label='all')\n",
    "\n",
    "# Save the regression tree\n",
    "plt.savefig('decision_tree_shows_release_year.png')\n",
    "\n",
    "# Separate DataFrame for movies\n",
    "movies_df = modified_netflix_df[modified_netflix_df['type'].str.strip() == 'MOVIE'].copy()\n",
    "\n",
    "# Split data into features and target variable\n",
    "X_movies = movies_df[['release_year']]\n",
    "y_movies = movies_df['runtime']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train_movies, X_test_movies, y_train_movies, y_test_movies = train_test_split(X_movies, y_movies, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a regression tree\n",
    "reg_tree_movies = DecisionTreeRegressor(max_depth=2, ccp_alpha=0.001)\n",
    "reg_tree_movies.fit(X_train_movies, y_train_movies)\n",
    "\n",
    "# Visualize the regression tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(reg_tree_movies, feature_names=['Movies Release Year'], filled=True, rounded=True, impurity=False, fontsize=8, precision=0, label='all')\n",
    "\n",
    "# Save the regression tree\n",
    "plt.savefig('decision_tree_movies_release_year.png')\n",
    "\n",
    "# Separate DataFrame for movies\n",
    "movies_df = modified_netflix_df[modified_netflix_df['type'].str.strip() == 'MOVIE'].copy()\n",
    "\n",
    "# Split data into features and target variable\n",
    "X_movies = movies_df[['runtime']]\n",
    "y_movies = movies_df['runtime']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train_movies, X_test_movies, y_train_movies, y_test_movies = train_test_split(X_movies, y_movies, test_size=0.2, random_state=10)\n",
    "\n",
    "# Create a regression tree\n",
    "reg_tree_movies = DecisionTreeRegressor(max_depth=2, ccp_alpha=0.001)  # Adjust the ccp_alpha value as needed\n",
    "reg_tree_movies.fit(X_train_movies, y_train_movies)\n",
    "\n",
    "# Visualize the regression tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(reg_tree_movies, feature_names=['Movies Runtime'], filled=True, rounded=True, impurity=False, fontsize=8, precision=0, label='all')\n",
    "\n",
    "# Save the regression tree\n",
    "plt.savefig('decision_tree_movies_runtime.png')\n",
    "\n",
    "# Separate DataFrame for shows\n",
    "shows_df = modified_netflix_df[modified_netflix_df['type'].str.strip() == 'SHOW'].copy()\n",
    "\n",
    "# Split data into features and target variable\n",
    "X_shows = shows_df[['runtime']]\n",
    "y_shows = shows_df['runtime']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train_shows, X_test_shows, y_train_shows, y_test_shows = train_test_split(X_shows, y_shows, test_size=0.2, random_state=10)\n",
    "\n",
    "# Create a regression tree\n",
    "reg_tree_shows = DecisionTreeRegressor(max_depth=2, ccp_alpha=0.001)  # Adjust the ccp_alpha value as needed\n",
    "reg_tree_shows.fit(X_train_shows, y_train_shows)\n",
    "\n",
    "# Visualize the regression tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(reg_tree_shows, feature_names=['Shows Runtime'], filled=True, rounded=True, impurity=False, fontsize=8, precision=0, label='all')\n",
    "\n",
    "# Save the regression tree\n",
    "plt.savefig('decision_tree_shows_runtime.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec039905-3205-4f68-b820-036e97c07256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 4 - ASSOCIATION RULES\n",
    "# import all the required packages\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import ast\n",
    "# ! pip install mlxtend --user\n",
    "import mlxtend\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from IPython.display import display\n",
    "\n",
    "# load the file\n",
    "df_new = pd.read_csv('raw_titles.csv')\n",
    "\n",
    "# data processing - genre was an object, converted it to a list. Relevant for the next step.\n",
    "genres_list = [ast.literal_eval(genre) for genre in df_new[\"genres\"]]\n",
    "df_new[\"genre_list\"] = genres_list\n",
    "\n",
    "# extracting the first genre from the genre column\n",
    "df_new[\"first_genre\"] = df_new[\"genre_list\"].apply(lambda x: x[0] if len(x) > 0 else None)\n",
    "\n",
    "# extracting the second genre from the genre column\n",
    "df_new[\"second_genre\"] = df_new[\"genre_list\"].apply(lambda x: x[1:2] if len(x) > 0 else None)\n",
    "\n",
    "# converting the second genre column to string as it was in list type\n",
    "df_new[\"second_genre_string\"] = df_new[\"second_genre\"].apply(\n",
    "    lambda x: \", \".join([str(item) for item in x]) if x is not None else None)\n",
    "\n",
    "# extracting the third genre from the genre column\n",
    "df_new[\"third_genre\"] = df_new[\"genre_list\"].apply(lambda x: x[2:3] if len(x) > 0 else None)\n",
    "\n",
    "# converting the third genre column to string as it was in list type\n",
    "df_new[\"third_genre_string\"] = df_new[\"third_genre\"].apply(\n",
    "    lambda x: \", \".join([str(item) for item in x]) if x is not None else None)\n",
    "\n",
    "# In a pivot table, values takes only int columns. This is why we convert the ID column. \n",
    "# Identify numeric parts of IDs\n",
    "df_new[\"id_numeric\"] = df_new[\"id\"].str.extract(\"(\\d+)\")\n",
    "\n",
    "# Convert numeric parts to integers\n",
    "df_new[\"id_numeric\"] = pd.to_numeric(df_new[\"id_numeric\"], errors=\"coerce\")\n",
    "\n",
    "# Pivot table with first genre column. This forms a binary matrix.\n",
    "pivot_table = pd.pivot_table(\n",
    "    df_new,\n",
    "    values=\"id_numeric\",\n",
    "    index=\"id\",\n",
    "    columns=\"first_genre\",\n",
    "    aggfunc=\"count\",\n",
    "    fill_value=0)\n",
    "\n",
    "# Pivot table with second genre column. This forms a binary matrix. \n",
    "# We have dropped the column where some data records did not have more than 1 genre in the list\n",
    "pivot_table2 = pd.pivot_table(\n",
    "    df_new,\n",
    "    values=\"id_numeric\",\n",
    "    index=\"id\",\n",
    "    columns=\"second_genre_string\",\n",
    "    aggfunc=\"count\",\n",
    "    fill_value=0,\n",
    ")\n",
    "pivot_table2.drop(columns = [\"\"], inplace = True)\n",
    "\n",
    "# Pivot table with third genre column. This forms a binary matrix. \n",
    "# We have dropped the column where some data records did not have more than 2 genre in the list\n",
    "pivot_table3 = pd.pivot_table(\n",
    "    df_new,\n",
    "    values=\"id_numeric\",\n",
    "    index=\"id\",\n",
    "    columns=\"third_genre_string\",\n",
    "    aggfunc=\"count\",\n",
    "    fill_value=0,\n",
    ")\n",
    "pivot_table3.drop(columns = [\"\"], inplace = True)\n",
    "pivot_table3\n",
    "\n",
    "#Summing the three pivot tables\n",
    "summed_df = pd.concat([pivot_table, pivot_table2, pivot_table3]).groupby('id').sum()\n",
    "\n",
    "# Creating itemsets using apriori, the minimum support here is 1% so there are enough association rules\n",
    "itemsets = apriori(summed_df, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# Creating rules based on itemsets (created in the previous step), here, taking metric as lift and minimum threshold\n",
    "# for this metric is 1. This is because, theoratically, Lift value > 1 implies a strong relationship between the two items\n",
    "rules = association_rules(itemsets, metric='lift', min_threshold=1)\n",
    "\n",
    "# Sorting the values by lift, in descending order\n",
    "final_output = rules.sort_values(by=['lift'], ascending=False)\n",
    "\n",
    "# if required, only see the columns that are important:\n",
    "# final_output = rules.sort_values(by=['lift'], ascending=False)\n",
    "# .drop(columns=['antecedent support', 'consequent support','conviction], inplace=True)\n",
    "\n",
    "# Displaying all the data records in the output\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(final_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
